version: '3'

services:
  namenode:
    build: .
    hostname: namenode
    container_name: hadoop-master
    environment:
      - ROLE=master
    ports:
      - "9870:9870" # HDFS Browser
      - "8080:8080" # Spark Master Browser
      - "8088:8088" # YARN Browser
      - "9000:9000" # HDFS RPC
      - "7077:7077" # Spark RPC
    volumes:
      - ./data/namenode:/tmp/hadoop-root/dfs/name
    networks:
      - hadoop_net

  datanode1:
    build: .
    container_name: hadoop-worker-1
    environment:
      - ROLE=worker
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=1G
    depends_on:
      - namenode
    volumes:
      - ./data/datanode1:/tmp/hadoop-root/dfs/data
    networks:
      - hadoop_net

  datanode2:
    build: .
    container_name: hadoop-worker-2
    environment:
      - ROLE=worker
    depends_on:
      - namenode
    volumes:
      - ./data/datanode2:/tmp/hadoop-root/dfs/data
    networks:
      - hadoop_net

  datanode3:
    build: .
    container_name: hadoop-worker-3
    environment:
      - ROLE=worker
    depends_on:
      - namenode
    volumes:
      - ./data/datanode3:/tmp/hadoop-root/dfs/data
    networks:
      - hadoop_net

  datanode4:
    build: .
    container_name: hadoop-worker-4
    environment:
      - ROLE=worker
    depends_on:
      - namenode
    volumes:
      - ./data/datanode4:/tmp/hadoop-root/dfs/data
    networks:
      - hadoop_net

networks:
  hadoop_net:
    driver: bridge
